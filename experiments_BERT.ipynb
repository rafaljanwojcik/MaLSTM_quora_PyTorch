{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_API_KEY = \n",
    "!pip install datasets wget transformers tensorboard wandb\n",
    "!wandb login $WANDB_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from time import time\n",
    "from datetime import date\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, BertTokenizer\n",
    "\n",
    "from modules.data import ImportData\n",
    "from modules.models import SiameseBERT2\n",
    "from modules.utils import collate_fn_bert, setup_logger, compute_metrics, compute_metrics_siamBERT, get_quora_huggingface\n",
    "from modules.train import CustomTrainer\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_info()\n",
    "\n",
    "path = Path('./logs/data/')\n",
    "if not (path/'dataset.csv').exists():\n",
    "    get_quora_huggingface(path)\n",
    "\n",
    "today = str(date.today())\n",
    "path = Path(f'./logs/train_job_{today}/')\n",
    "emb_path = Path('./logs/embeddings')\n",
    "data_path = Path('./logs/data')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-model_name\", \"--model_name\", type=str, help=\"Name of trained model. Needed only for correct logs output\", default='bert')  \n",
    "parser.add_argument(\"-log\", \"--logdir\", type=str, help=\"Directory to save all downloaded files, and model checkpoints.\", default=path)  \n",
    "parser.add_argument(\"-df\", \"--data_file\", type=str, help=\"Path to dataset.\", default=data_path/\"dataset.csv\")\n",
    "parser.add_argument(\"-s\", \"--split_seed\", type=int, help=\"Seed for splitting the dataset.\", default=44)\n",
    "parser.add_argument(\"-b\", \"--batch_size\", type=int, help=\"Batch Size.\", default=16)\n",
    "parser.add_argument(\"-epo\", \"--n_epoch\", type=int, help=\"Number of epochs.\", default=4)\n",
    "parser.add_argument(\"-bert_cls\", \"--bert_cls\", type=str, help=\"Type of BERT trained (classificator, siamese).\", default='siamese')\n",
    "parser.add_argument(\"-bert_backbone\", \"--bert_backbone\", type=str, help=\"Either path to the model, or name of the BERT model that should be used, compatible with HuggingFace Transformers.\", default='bert-base-uncased')\n",
    "\n",
    "args = parser.parse_args('')\n",
    "args.logdir = args.logdir/(args.bert_cls+'_'+args.model_name)\n",
    "model_path = args.logdir/'best_model/'\n",
    "if not args.logdir.exists():\n",
    "    os.makedirs(args.logdir)\n",
    "\n",
    "logger = setup_logger(str(args.logdir/'logs.log'))\n",
    "logger.info(\"Begining job. All files and logs will be saved at: {}\".format(args.logdir))\n",
    "\n",
    "\n",
    "logger.info('Reading Dataset and splitting into train and test datasets with seed: {}'.format(args.split_seed))\n",
    "data = ImportData(str(args.data_file))\n",
    "data.train_test_split(seed=args.split_seed)\n",
    "\n",
    "\n",
    "logger.info('')\n",
    "logger.info('Number of training samples        :{}'.format(len(data.train)))\n",
    "logger.info('Number of validation samples      :{}'.format(len(data.test)))\n",
    "logger.info('')\n",
    "\n",
    "model = SiameseBERT2.from_pretrained(\"bert-base-uncased\") if args.bert_cls=='siamese' else BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "logging_num = data.train.shape[0]/(torch.cuda.device_count() * args.batch_size)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(args.logdir/'results'),          # output directory\n",
    "    overwrite_output_dir = True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    save_steps= logging_num//2, #logging_num/4,\n",
    "    save_total_limit = 8,\n",
    "    eval_steps = 500,#logging_num//10,\n",
    "    logging_steps = 500,#logging_num//10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_first_step = True,\n",
    "    num_train_epochs=4,              # total # of training epochs\n",
    "    per_device_train_batch_size=args.batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01, # strength of weight decay\n",
    "    logging_dir=str(args.logdir/'logs'),            # directory for storing logs\n",
    ")\n",
    "\n",
    "trainer_class = CustomTrainer if args.bert_cls == 'siamese' else Trainer\n",
    "trainer_args = {'model':model, 'args':training_args, \n",
    "                'data_collator':lambda x: collate_fn_bert(x, tokenizer, args.bert_cls),\n",
    "                'train_dataset':data.train.values,\n",
    "                'eval_dataset':data.test.values, \n",
    "                'compute_metrics':compute_metrics_siamBERT if args.bert_cls == 'siamese' else compute_metrics}\n",
    "if args.bert_cls == 'siamese':\n",
    "    trainer_args['logger'] = logger\n",
    "trainer = trainer_class(**trainer_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir ./logs/train_job_2020-09-23/siamese_bert/logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
